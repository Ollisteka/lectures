## Лингвистические основы информатики (ЛОИ)

> *12.02.2019*

##### Орг. вопросы

- годовой курс: зачёт+экзамен;
- Петрова Елена Александровна, elena.petrova@urfu.ru;
- консультации по понедельникам в 16:10 на кафедре алгебры и фундаментальной информатики.

##### Рекомендуемая литература

- [Языки, грамматики, распознаватели](http://kadm.imkn.urfu.ru/files/shurzam.pdf) (Шур, Замятин) - основной учебник (много багов!)
- Ахо, Лам, Сети, Ульман "Компиляторы. Принципы, технологии, инструменты" (Dragon book)
- Ахо, Ульман "Теория синтаксического анализа, перевода и компиляции"
- Cooper K. Engineering a Compiler.

>  [репозиторий с .djvu книгами](https://github.com/afrolovskiy/compilers_labs/tree/master/literature)

##### Чем будем заниматься?

— Теорией компиляции. Узнаем:

- что такое язык;
- что такое компилятор;
- что делает компилятор с языком.

В итоге будем знать, как работают и как написать *(в теории)* компиляторы.



**Немного комментариев и истории:**

> Даже разбор формулы в Экселе использует какие-то приёмы компиляции!

> В 50-x годах людям надоело писать на ассемблере, и они начали думать. К 60-м придумали.
>
> Дейкстра - двигатель прогресса, потому что придумал <u>теорию</u>, а не какое-то специфичное для задачи решение.



### Что такое компилятор?

По-простому – переводчик с языка на язык. Можно рассматривать как чёрный ящик с каким-то входом, выходом и магией внутри.

Принято разделять его работу на 2 фазы:

​	$\downarrow$  *исходный текст* 

фронтенд: **анализ** исходного текста. Если есть ошибки, то останавливаемся.

​	$\downarrow$  *промежуточное представление*

 бэкенд:  **синтез** - генерация программы, которая нам нужна вместе с какими-то <u>оптимизациями</u>.

​	$\downarrow$  *целевой код*



Заниматься будем фронтендом!



####Блок анализа

​	$\downarrow$  *исходный текст* 

лексический анализ: разбиваем текст на токены – знаки, переменные, идентификаторы.

​	$\downarrow$  *токены*

синтаксический анализ (парсер)

​	$\downarrow​$  *синтаксическое дерево*

семантический анализ: проверка типов.

​	$\downarrow​$  *промежуточное представление*



####Язык

1. Лексика - слова

2. Синтаксис – правила построения предложений

3. Семантика - типы и подходящие им операции



**Таблица символов** - информация о переменных, константах, функциях. Используется на всех шагах анализа.

Заполнение:

- лексика (?): встречаем новый символ - записываем имя переменной и указываем место первого появления.

- семантика: тип, место хранения, время объявления



Написанию компилятора предшествует описание языка.

Рассмотрим язык с условным оператором. Что есть условный оператор с точки зрения синтаксиса? Опишем это с помощью **форм Бэкуса–Наура**[^1].


```
<условный оператор>::== if <логическое выражение> <список операторов> { else <список операторов> }

<список операторов>::== <оператор>|<оператор>;<список операторов>

...

<идентификатор>::== [a-zA-Z]\w*
```

> **Обозначения**
>
> | {}  — альтернатива
>
> <>    — синтаксическая категория
>
> ::==  — выводимость



#### Грамматика

**[Порождающая] грамматика** - объект математический. Основной способ описания синтаксиса и лексики (частный случай синтаксиса).

<u>Опр</u>. Грамматика $G =\:<\Sigma, \Gamma, P, S>​$, где

- $\Sigma$ – терминальный алфавит (выходной);
- $\Gamma$ – нетерминальный алфавит (вспомогательный);
- $P$ – множество правил вывода;
- $S \in \Gamma$ – выделенный нетерминал – аксиома (<u>одна</u>).



**Соглашения**

- $a, b, c, \:…​$ - терминальные символы (if - терминал);
- $x, y, z, \:…​$ - терминальные слова (последовательности терминальных символов);
- $A, B, C, \:…​$ - нетерминальные символы;
- $X, Y, Z, \:…​$ - слова из любых символов;
- $\alpha, \beta, \gamma, \:...$ - совокупные слова, содержащие как терминальные, так и нетерминальные символы.
- $\lambda​$ - пустое слово.



#### Выводимость

**Правило вывода**: $\alpha \rightarrow \beta$, $\alpha, \beta \in (\Sigma \cup \Gamma)^*$, точнее $\alpha \in (\Sigma \cup \Gamma)^*\Gamma(\Sigma \cup \Gamma)^*$ 

​									               $\uparrow$ *в альфе должен быть хотя бы 1 нетерминал!*

Таким образом, терминальные символы стоит понимать как символы, из цепочек которых ничего нельзя вывести.

Основная функция этого правила – порождение языка.

<u>Опр</u>. Цепочка $\gamma$ ***непосредственно* выводима** из цепочки $\sigma$, если $\gamma = \delta_1\beta \delta _2$, $\sigma = \delta _1 \alpha \delta _2$ и $(\alpha \rightarrow \beta) \in P$ 

Обозначается как $\sigma \Rightarrow \gamma$ (или, при необходимости, $\gamma \Leftarrow \sigma$).

> В цепочке сигма есть подпоследовательность альфа, которую можно заменить бетой
>
> Выводимость - отношение на множестве цепочек. Рефлексивно-транзитивное замыкание $\sigma \Rightarrow \gamma.$ Возможность вывести одну цепочку из другой за некоторое число шагов

<u>Опр</u>. $\gamma​$ **выводима** из $\sigma​$ если существует последовательность цепочек $\eta_0, ..., \eta_n, n \ge 0​$ такая, что $\eta _0 = \sigma, \eta _n = \gamma, \eta _{i-1} \Rightarrow \eta _i​$ $ (\sigma \Rightarrow ^*\gamma)​$

Последовательность $\eta_0, ..., \eta_n$ – **вывод**

Получается, что грамматика для нас — просто набор правил вывода. Потому что всё остальное мы зафиксировали в обозначениях.



<u>Опр</u>. **Язык**, порождённый грамматикой $G = \:<\Sigma, \Gamma, P, S>$ : $\{w \in \Sigma^*|S \Rightarrow ^*w\}$ — множество терминальных цепочек таких, что их можно вывести из аксиомы.

<u>Опр</u>. $\eta_0, ..., \eta_n: \eta_0=s, \eta_n=w, \eta _{i-1} \Rightarrow \eta _i$, $\eta_i$ – форма (шаг)



**Пример**

Убедимся в том, что язык $L = \{a^n b^n | n \in \N_0\}$ порождается грамматикой $G = <{S}, {a, b}, P, S>$, в которой P состоит из следующих правил вывода:

- $S \rightarrow aSb$ 
- $S \rightarrow \lambda​$

Рассмотрим вывод терминальной цепочки:

$S \Rightarrow aSb \Rightarrow aaSbb \Rightarrow aabb$

>  $ab$ - терминалы (см. соглашения)

Но тогда и слова $a^n b^n$ могут быть получены после $n$ применений первого правила вывода к аксиоме $S$ и затем однократным применением второго правила.

**Ещё пример**

$S \rightarrow ABS|\lambda​$			$S \rightarrow SS|a|b|\lambda​$

$AB \rightarrow BA​$

$A \rightarrow a​$

$B \rightarrow b​$



$S \Rightarrow ABS \Rightarrow ABABS \Rightarrow ^* (AB)^nS \Rightarrow (AB)^n​$

Можем перейти к терминалам

$S \Rightarrow ^*ABABAB \Rightarrow ABBAAB \Rightarrow abbaab$

Хотим загнать буквы А в конец, а B в начало. Будем менять местами буквы по второму правилу.

$ABABAB \Rightarrow BA\_AB\_AB \Rightarrow B\_AB\_AAB \Rightarrow BBAA\_AB\_ \Rightarrow \:...​$



> *19.02.2019*

```
pos = init + rate * 60;

// после лескического анализа превращается в...
id,15 <=> <id,2><+><id,3><*><const><;>
// cинтаксическому анализу всё равно, как называется переменная

// после ситанксического анализа превращается в...
    =
   / \
id,1   +
      / \
   id,2  *
        / \
     id,3 const
//после семантического добавятся какие-то атрибуты
```



На каждой стадии – новый язык. Значит, нужны новые способы порождения\описания. А этот способ порождает распознаватель.

### Иерархия Хомского-Шютценберже

|      | Вид грамматики           | Распознаватель                                         | Класс языков            |
| ---- | ------------------------ | ------------------------------------------------------ | ----------------------- |
| 0    | Грамматика обычного вида | МТ                                                     | Рекурсивно перечислимые |
| 1    | Контекстно-зависимые     | МТ с линейно ограниченной памятью (LBA)                | КЗЯ                     |
| 2    | Контекстно-свободные     | Недетерминированный автомат с магазинной памятью (PDA) | КСЯ                     |
| 3    | Праволинейные            | ДКА                                                    | Регулярные языки        |

<u>Опр</u>. Контекстно-зависимая грамматика — все правила имеют вид $\alpha A\gamma \rightarrow \alpha \beta\gamma$ (у терминала имеется контекст, который сохраняется при его раскрытии) .

<u>Опр</u>. Язык обладает свойством $P$, если $\exists$ грамматика со свойством $P$, его порождающая.

<u>Опр</u>. Контекстно-свободная грамматика — все правила имеют вид $A \rightarrow \beta$ (частный случай КЗГ, когда оба контекста пусты).

<u>Опр</u>. Праволинейные грамматики — все правила имеют вид $A \rightarrow aB$ или $A \rightarrow\lambda $ справа либо лямбда, либо терминал+нетерминал.

Вспомним пример. Кажется, что это грамматика обычного вида.

$S \rightarrow ABS|\lambda​$			$S \rightarrow SS|a|b|\lambda​$

$AB \rightarrow BA​$

$A \rightarrow a​$

$B \rightarrow b$

Построим КСГ, которая породит язык выше. Порождаем цепочки, где букв $B$ на одну больше, чем $a$.

Из $А$ должны выводиться строчки, где на одну $a​$ больше

$S \rightarrow aB|bA$

$A \rightarrow aS|bAA$

$B\rightarrow bS|aBB$

$A \rightarrow a$

$B \rightarrow b$

$abba : \:S \rightarrow aB \rightarrow abS \rightarrow abbA \rightarrow abba ​$

Иерархия: регулярные $\subset$ КСЯ $\subset$ КЗЯ $\subset$ Rec $\subset​$ RecEn[^2].



### Контекстно-свободные грамматики и языки

<u>Опр</u>. Упорядоченное дерево — дерево с заданным линейным порядком со следующими свойствами:

1. Если $x​$ - сын узла $y​$, то $x \ge  y​$
2. Если $x \le y$ и они братья, то для всех сыновей $z$ узла $x$: $z\le y$

> Порядок, возникающий при обходе в глубину слева направо

**Пример**:

$S \rightarrow SS|(s)|\lambda​$

$(( ))​$

$S  \rightarrow SS  \rightarrow (s)  \rightarrow ((s))  \rightarrow (())$

```
           S₁
         /   \
        S₂    S₄
	    |	 / | \
        λ₃ (₅  s₆  )₁₁
             / | \
          (₇   s₈  )₁₀
               |
               λ₉
```

<u>Опр</u>. Дерево вывода цепочки $\omega$ в $G =\:<\Sigma, \Gamma, P, S>$ —  упорядоченное  дерево со следующими свойствами:

1. Узлы – нетерминалы, корень – аксиома, листья – терминалы или $\lambda​$, причём у листьев, помеченных пустым словом нет братьев.

   > Если есть братья, то $\lambda a == a​$

2. Если у узла $x$ все сыновья это некоторый набор  $y_1, \: … \: y_n$, таких, что $y_1 \le \: ...\: \le y_n$, и узлы $x$​, $y_1, \: … \: y_n$ помечены символами $X, Y_1, \: … \: Y_n$, то $(X \rightarrow Y_1, \: … \: Y_n) \in P​$.

   > Применили правило, в дереве появился куст вывода

3. Если все листья дерева имеют метки $a_1 \le a_2 \le \: … \le \: a_n$, то $\omega = a_1…a_n$

<u>Опр</u>. Вывод цепочки $\omega (S \Rightarrow \alpha_1  \Rightarrow  \: … \:  \Rightarrow \alpha_n=\omega)​$ в $G =\:<\Sigma, \Gamma, P, S>​$ представлен деревом вывода $T​$, если $\exists​$ набор стандартных поддеревьев $T_1, … T_n​$ таких, что на упорядоченных листьях дерева $T_i ​$ написана форма $\alpha_i​$.

<u>Опр</u>. Стандартное поддерево $T' $дерева $T$, если:

1. корень $T'​$ - корень $T​$

2. Если узел $x​$ дерева $T​$$ \in T'​$, то либо $x​$ - лист, либо все сыновья $x​$ в $T​$ $\in T'​$

   > Если с узлом лежит хотя бы один его сын, то и все его сыновья тоже лежат.

**Пример по последнему языку:**

![Стандартные поддеревья](.\images\standard_subtrees.jpg)



Наша любимая грамматика, которая порождает арифметику:

$E \rightarrow E+E|E*E|(E)|x$

$x+x*x$

```
   E
  /|\
E  +  E   - этот куст можно передвинуть влево, получится два разных дерева
|    /|\    для одного и того же. Плохо.
x   E * E
    |   |
    x   x
```

<u>Опр</u>. Грамматика однозначна, если $\forall \omega$,  выводимой в грамматике, $\exists!$ дерево вывода.

Следующая грамматика однозначна и эквивалентна предыдущей

$E \rightarrow E + T|T​$

$T \rightarrow T*F|F​$

$F \rightarrow (E) |x​$

1. Правосторонний вывод и r-формы:$E \rightarrow E + T \rightarrow E+T*F \rightarrow E+T*x \rightarrow E+F*x \rightarrow E+x*x\rightarrow   T+x*x \rightarrow F+x*x \rightarrow x+x*x$
2. Левосторонний вывод и l-формы:$E \rightarrow E+T\rightarrow T+T \rightarrow F+T \rightarrow x+T \rightarrow x+T*F \rightarrow x+F*F \rightarrow x+x*F\rightarrow x+x*x $

Плата за однозначность - увеличение длины вывода.



>  *26.02.19*

<u>Теорема</u>. Праволинейная грамматика порождает регулярный язык

Д-во: 

>  построим автомат и по теореме Клини - готово

$G =\:<\Sigma, \Gamma, P, S>​$ 

Конечный автомат: $A =\:(\Sigma, \Gamma, \delta,  S, F)$,

$F = \{A \in \Gamma | (A \rightarrow \lambda) \in P\}$  — терминальные состояния - такие нетерминалы, из которых выводится пустое слово

$\delta(A,a)=B \iff (A \rightarrow aB) \in P$ — переход возможен, если есть такое правило вывода

$\omega = a_1…a_n$:         $S \rightarrow a_1A_1 \rightarrow a_1a_2A_2 \rightarrow … \rightarrow a_1…a_nA_n \rightarrow a_1…a_n$ 

$\blacksquare​$



>  **Пример**
>
>  $a(b+cc)*$ — чтобы построить грамматику, проще сначала нарисовать автомат, распознающий этот язык. Обозначим все состояния нетерминальными символами. А дальше - как в теореме выше, только в обратную сторону.
>
>  $S \rightarrow aA$
>
>  $A \rightarrow bA|cB|\lambda​$
>
>  $B \rightarrow cA$



### Преобразования грамматик

>  Хотим научиться удалять лишние вещи, которые не несут никакой пользы.

#### Приведённые грамматики

<u>Опр</u>. Нетерминал $A \in \Gamma$ называется **производящим**, если $A \Rightarrow_G^*\omega$ .

> == из него можно получить терминальную цепочку.

<u>Опр</u>. Нетерминал  $A \in \Gamma$ называется **достижимым**, если $S \Rightarrow_G^*\alpha A \beta$ 

> == его можно получить из аксиомы.

<u>Опр</u>. Грамматика **приведённая**, если все её нетерминалы достижимые и производящие.

**Пример**

$S \rightarrow bAc|AcB$

$A \rightarrow abC$

$B \rightarrow Ea​$

$C \rightarrow BD$

$D \rightarrow CCa$

$E \rightarrow Fbb​$

$F \rightarrow a$

Производящие *(**p**roducing)*: $\Gamma_p = \{F, E, B\}$.

> Если среди производящих нетерминалов нет аксиомы, то язык пустой. 

Достижимые *(**r**eachable)*: $\Gamma_r = \{S,A,B,C,E,D,F\}​$



**Нахождение $\Gamma_r​$:**

- $\Gamma_r^1 \leftarrow S$;

- $\Gamma_r^n = \Gamma_r^{n-1} \cup \{A|(B \rightarrow \alpha A \beta) \in P, \beta \in \Gamma_r^{n-1})\}$.

  > смотрим, какие нетерминалы есть справа и добавляем те, которых ещё нет в  $\Gamma_r$

**Нахождение $\Gamma_p$:**

- $\Gamma_p^1 \leftarrow \{A|(A \rightarrow \omega) \in P\}$;

- $\Gamma_p^n = \Gamma_p^{n-1} \cup \{A|(A \rightarrow \gamma) \in P, \gamma \in (\Sigma \cup \Gamma_p^{n-1})\}$.

  >  смотрим на достижимые из $\Gamma_p^{n-1}$ нетерминалы;



<u>Теорема</u>. Для любой КСГ $G​$ существует эквивалентная[^3] ей приведённая грамматика.

Д-во:

КСГ $G =\:<\Sigma, \Gamma, P, S>​$ 

Находим  $\Gamma_p​$:

- если $S \notin \Gamma_p$, то $G' = (\Sigma, \emptyset,  \emptyset, \emptyset)$

- иначе $\tilde G= (\Sigma, \Gamma_p, \tilde P, S) $

  $ \tilde P = \{(A \rightarrow \gamma) \in P | A, \gamma \in (\Sigma \cup \Gamma_p)^*\}$

Находим  $(\Gamma_p)_r​$

>  Выкидываем правила вывода, которые и так не участвовали в выводе терминальных цепочек

$(\Gamma_p)_r​$ - достижимы в  $\tilde G​$, $G'​$, производящие в $\tilde G​$, $G​$

$A \in (\Gamma_p)_r$:  $S \Rightarrow_{\tilde G}^* \alpha A \beta  \Rightarrow_{\tilde G}^* uwv​$

$\blacksquare$



**Пример**

$S \rightarrow ab|bAc$

$A \rightarrow CB$

$B \rightarrow aSA​$

$C \rightarrow bC|d$



$\Gamma_p = \{C, S\}$

$(\Gamma_p)_r = \{S\}​$

$G' = \{S \rightarrow ab \}$



> Больше не будем рассматривать неприведённые грамматики



#### $\lambda$-свободные грамматики

<u>Опр</u>. $A \in G$ — **аннулирующий**, если $A \Rightarrow^* \lambda$.

<u>Опр</u>. $Ann(G)​$ — множество аннулирующих нетерминалов.

> Хотим, чтобы это множество было пустым. Ну или хотя бы только с аксиомой. Потому что тогда нам жить станет прощею

> Чтобы от аннулирующих нетерминалов избавиться, нужно их найти



**Пример**

$D \rightarrow aBC|AE$

$A \rightarrow bC|\lambda​$

$B \rightarrow ACA​$

$C \rightarrow \lambda​$

$E \rightarrow CA$

$D \rightarrow bE|c$



$Ann(G)$:

1. $\{A, C\}$
2. $\{A,C,B,E\}$
3. $\{A,C,B,E, S\}​$



<u>Опр</u>. **$\lambda$-свободная** грамматика — грамматика, которая либо не содержит аннулирующих правил вида $(A \rightarrow \lambda)$, либо содержит единственное такое правило $(S \rightarrow \lambda)$ и $S$ не встречается в правых частях правил вывода.

<u>Теорема</u>. Любая грамматика эквивалентна $\lambda$-свободной грамматике

Д-во:

> Сначала построим, потом всё покажем

$G =\:<\Sigma, \Gamma, P, S>$ 

0. Если $\lambda \in L(G)$, то $\Gamma' = \Gamma \cup S'$, $P'=P\cup\{(S' \rightarrow \lambda), (S' \rightarrow S))\}$

   Иначе $\Gamma = \Gamma '$, $S  = S'$, $P=P'$

> Смысл: добавим аксиому, которая справа встречаться нигде не будет???

1. Построим $Ann(G)$.

2. Рассмотрим бинарное отношение на множестве форм:

   $\beta \preceq \gamma​$, если $\beta​$ - подпоследовательность $\gamma​$ и все символы $\gamma​$, которых нет в $\beta​$, аннулирующие.

   $P'=\{(A \rightarrow \beta) | (A \rightarrow \gamma) \in P, \beta \preceq \gamma, \beta \neq \lambda\}​$

   > Взяли все исходные правила. В новую грамматику положили их "части"-подстроки. 

3. Видно, что аннулирующие правила мы не взяли, поэтому она  $\lambda$-свободная по определению.

$L(G) = L(G')$?

1. $w \in L(G')​$

   $S \Rightarrow_{G'} \alpha_i  \Rightarrow_{G'}...  \Rightarrow_{G'} \alpha_n = w​$

   $\alpha_{i_{G'}} \Rightarrow \alpha_{i+1}(A \rightarrow \beta) \in P' \Rightarrow $ в $G$ $\exists (A \rightarrow \gamma) \in P, \beta  \preceq \gamma$

   > как построить такую же цепочку, используя другие правила? Непонятно.

2. $w \in L(G)​$

   > Что означает этот треугольник???
   >
   > ![Магический треугольник](.\images\magic_triangle.jpg)



$\blacksquare$



> *05.03.2019*

### Нормальная форма Хомского

>  Нужна для доказательства важной теоремы, понадобится для алгоритма разбора.

<u>Опр.</u> Грамматика находится в ХНФ, если все её не аннулирующие правила вывода имеют вид $A \rightarrow BC$ (справа ровно 2 нетерминала) или$ A \rightarrow a$'.

<u>Теорема</u>. Любая КС грамматика эквивалентна некоторой грамматике в ХНФ.

<u>Д-во</u>. *Конструктивное*.

$G =\:<\Sigma, \Gamma, P, S>​$ 

Пусть $G$ — исходная грамматика ($\lambda$-свободная)

1. Для всех правил грамматики, у которых в правой части хотя бы 2 символа сделаем следующее: 

  > $\forall A\rightarrow X_1...X_n$, $n>=2​$

  - если $X_i $— терминал, добавим новый нетерминал $X_i'$ и правило $X_i' \rightarrow X_i$. Затем заменим вхождение терминала во всех правых частях на новый нетерминал.

  >  Избавляемся от правил, где справа много терминалов.

2. $A \rightarrow B $ — цепные правила. Что делать с ними? Заменим правую часть на всё, что выводится из $B$. Но что, если есть цепочка $A \rightarrow B  \rightarrow  …  \rightarrow  A$ (цикл)? Сначала нужно от них избавиться.

     

   <u>Опр</u>. Грамматика **циклическая**, если существует такой нетерминал $А$, что за какое-то ненулевое количество шагов из него выводится он сам. В противном случае — **ациклическая **.

   <u>Лемма</u>. Любая грамматика эквивалентна некоторой ацикличной.

   <u>Д-во</u>.Пусть $A_1 \Rightarrow A_2  \Rightarrow …  \Rightarrow A_n  \Rightarrow A_1$

   Заменим все $A_i$ на $A$ и удалим правила $A \Rightarrow A$. Получилась $G'$. Готово.

   Почему работает: $w \in L(G) \iff w \in L(G')$

   $\Rightarrow$ Вывод в $G'$ получается стиранием индексов.

   $\Leftarrow$ Пусть $A$ участвовал в выводе $w$. Пусть нетерминал $A$ появлялся в какой-то правой части: $B \rightarrow \alpha A \beta$, $ A \rightarrow \gamma$. Если такие правила были в $G'$, то в $G$ существуют правила вывода $(B \rightarrow \alpha A_i \beta)$, $(A_j \rightarrow \gamma)$. Но мы знаем, что из $A_i \Rightarrow_G^* A_j$ (*Если не совпадает с гаммой, то крутимся по циклу*).

   

3. Если справа хотя бы 3 нетерминала, то заменим второй нетерминал на новый, а из него будем выводить хвост.

$\blacksquare$



**Пример**

$S \rightarrow AB|aAb$

$A \rightarrow bB|aBC|\lambda$

$B \rightarrow AS|bA|a$

$C \rightarrow b$

Выведем $\lambda$-свободную грамматику. $Ann(G) = \{A\}$. 

$S \rightarrow AB|B|\_aAb\_|\_ab\_​$

$A \rightarrow \_bB\_|\_aBC\_$

$B \rightarrow  AS|S|\_bA\_|b|a$

$C \rightarrow  b​$

Приведём к ХНФ. Добавим $ A'  \rightarrow a$ и $B' \rightarrow b$:

$S \rightarrow AB|B|A'AB'|A'B'​$

$A \rightarrow B'B|A'BC$

$B \rightarrow  AS|S|B'A|b|a​$

$C \rightarrow b$

Найдём цикл: $S  \rightarrow B  \rightarrow  S$. Заменяем $B$ на $S$, и подставляем в $S$ всё, что выводится из $B$

$S \rightarrow AS|A'AB'|A'B'|B'A|b|a​$

$A \rightarrow B'S|A'SC​$

$C \rightarrow  b​$

Заменим тройные нетерминалы на двойные, добавим $D \rightarrow AB'​$ и $E  \rightarrow  A'SC​$

$S \rightarrow AS|A'D|A'B'|B'A|b|a​$

$A \rightarrow B'S|D$

$C \rightarrow  b$



### Свойства КСЯ

<u>Лемма Огдена</u>. Пусть есть $L$ — КСЯ. Тогда $\exists m \in \N:\: \forall w \in L$ в которых помечено не менее $m$ позиций, представимо в виде $w=uxzyv$

1. $xy$ содержит хотя бы одну помеченную позицию;
2. $xzy$ содержит не более $m$ помеченных;
3. $ux^{n}zy^nv \in L $  $\forall n \in \N$ (*накачка*).

> Помечено - выбираем какие-то символы

<u>Д-во</u>. $G =\:<\Sigma, \Gamma, P, S>$ , $L = L(G)$

Пусть $L$ порождается грамматикой в ХНФ, $m = 2^{|\Gamma|+1}$. Рассмотрим такое слово $w \in L$, что $|w| \ge m$ и пометим в нём не менее $m$ позиций. Рассмотрим дерево вывода слова $w$ (треугольник). Построим путь вывода слова $w$ в G:

- Корень (вершина треугольника) — аксиома. Принадлежит пути.

- Из двух (потому что ХНФ) потомков выберем того, из которого выводится больше выделенных позиций.

  > **Точка ветвления** — узел, у которого из обоих потомков выводится подслова w с помеченными позициями

  >  ВАЖНО: каждая следующая точка ветвления порождает не менее половины помеченных позиций $w$ от тех, что порождает предыдущая точка. Доказать можно по индукции.

в $pw​$ (*путь*) не менее $|\Gamma| + 1​$ точек ветвления. Среди всех точек ветвления рассмотрим последние точки. Но у нас всего $|\Gamma|​$ нетерминалов, значит, хотя бы 2 узла совпали – имеют одинаковую метку. Назовём её $A​$. (Находится близко к листьям! Иначе не можем что-то гарантировать)

$w_1$ — точка ветвления $\Rightarrow$ $x$ или $y$ содержит хотя бы одну помеченную позицию. (*$x, y$ - подслова*)

$A \Rightarrow^* z$, $A \Rightarrow^* xzy$ 

> Тут ещё какие-то правила

> Рандомный комментарий: для всех слов высота дерева вывода одинаковая! Для ХНФ.

$\blacksquare$

**Пример**

$S \rightarrow AB​$

$A \rightarrow AB|a$

$B \rightarrow BS|b$

> ![some example](.\images\some_example.jpg)

# Сноски

[^1]: Будем их использовать, чтобы не терять связь грамматики и компиляции.
[^2]: Recursively Enumerable
[^3]: с таким же деревом вывода